{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "!cd .."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T18:40:22.585158Z",
     "end_time": "2023-07-10T18:40:22.624157Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-10T18:40:22.627156Z",
     "end_time": "2023-07-10T18:40:24.931033Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.vectorstores import Milvus\n",
    "import os\n",
    "from langchain.callbacks import wandb_tracing_enabled\n",
    "from datetime import datetime\n",
    "from langchain.callbacks import WandbCallbackHandler, StdOutCallbackHandler\n",
    "\n",
    "from constants import (EMBEDDING_MODEL_NAME, MODEL_ID, MODEL_BASENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-10T18:40:24.933033Z",
     "end_time": "2023-07-10T18:40:24.947032Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s - %(filename)s:%(lineno)s - %(message)s\", level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-10T18:40:33.934155Z",
     "end_time": "2023-07-10T18:40:33.954670Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_cpu_model(model_id, model_basename):\n",
    "    model_path = hf_hub_download(repo_id=model_id, filename=model_basename)\n",
    "\n",
    "    # Callbacks support token-wise streaming\n",
    "    session_group = datetime.now().strftime(\"%m.%d.%Y_%H.%M.%S\")\n",
    "\n",
    "    wandb_callback = WandbCallbackHandler(\n",
    "        job_type=\"inference\",\n",
    "        project=\"langchain_callback_demo2\",\n",
    "        group=f\"minimal_{session_group}\",\n",
    "        name=\"llm\",\n",
    "        tags=[\"test\"],\n",
    "    )\n",
    "\n",
    "    callback_manager = CallbackManager([StreamingStdOutCallbackHandler(), StdOutCallbackHandler(), wandb_callback])\n",
    "    # Verbose is required to pass to the callback manager\n",
    "\n",
    "    model = LlamaCpp(model_path=model_path, n_ctx=2048, max_tokens=2048, temperature=0, repeat_penalty=1.15,\n",
    "                     callback_manager=callback_manager, verbose=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-10T18:44:14.147079Z",
     "end_time": "2023-07-10T18:44:40.619718Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 18:44:14,146 - INFO - SentenceTransformer.py:66 - Load pretrained SentenceTransformer: hkunlp/instructor-large\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 18:44:17,452 - INFO - 2111476880.py:3 - embedding model loaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:bvbixuet) before initializing another..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">llm</strong> at: <a href='https://wandb.ai/aditya/langchain_callback_demo2/runs/bvbixuet' target=\"_blank\">https://wandb.ai/aditya/langchain_callback_demo2/runs/bvbixuet</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20230710_184202-bvbixuet\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Successfully finished last run (ID:bvbixuet). Initializing new run:<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.5"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>D:\\Learning\\git\\local-chatbot-cpu\\notebooks\\wandb\\run-20230710_184418-p72e8ewz</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/aditya/langchain_callback_demo2/runs/p72e8ewz' target=\"_blank\">llm</a></strong> to <a href='https://wandb.ai/aditya/langchain_callback_demo2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/aditya/langchain_callback_demo2' target=\"_blank\">https://wandb.ai/aditya/langchain_callback_demo2</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/aditya/langchain_callback_demo2/runs/p72e8ewz' target=\"_blank\">https://wandb.ai/aditya/langchain_callback_demo2/runs/p72e8ewz</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n",
      "2023-07-10 18:44:39,435 - INFO - 2111476880.py:7 - text generator model loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load the embedding model\n",
    "embeddings = HuggingFaceInstructEmbeddings(model_name=EMBEDDING_MODEL_NAME, model_kwargs={\"device\": 'cuda'})\n",
    "logging.info('embedding model loaded.')\n",
    "\n",
    "# Load text generator model\n",
    "llm = load_cpu_model(MODEL_ID, MODEL_BASENAME)\n",
    "logging.info('text generator model loaded.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-10T18:47:11.404990Z",
     "end_time": "2023-07-10T18:47:11.417002Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_llm_generation_langchain(question):\n",
    "    vector_store = Milvus(embedding_function=embeddings,\n",
    "                          connection_args={\"host\": \"localhost\", \"port\": \"19530\"},\n",
    "                          collection_name='PAN',\n",
    "                          index_params={\"metric_type\": \"IP\", \"params\": {\"nprobe\": 10}})\n",
    "\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vector_store.as_retriever(),\n",
    "                                     return_source_documents=True)\n",
    "\n",
    "    # Get the answer from the chain\n",
    "    res = qa(question)\n",
    "    answer, docs = res[\"result\"], res[\"source_documents\"]\n",
    "\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-10T18:18:43.052109Z",
     "end_time": "2023-07-10T18:18:43.058107Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_PROJECT\"] = \"langchain-testing\"\n",
    "\n",
    "# unset the environment variable and use a context manager instead\n",
    "if \"LANGCHAIN_WANDB_TRACING\" in os.environ:\n",
    "    del os.environ[\"LANGCHAIN_WANDB_TRACING\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-10T14:18:36.391231Z",
     "end_time": "2023-07-10T14:20:20.990689Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Streaming LangChain activity to W&B at https://wandb.ai/aditya/langchain-testing/runs/cavseyhs\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: `WandbTracer` is currently in beta.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Please report any issues to https://github.com/wandb/wandb/issues with the tag `langchain`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What is the purpose of a PAN card?"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello! How can I assist you today?"
     ]
    }
   ],
   "source": [
    "# enable tracing using a context manager\n",
    "with wandb_tracing_enabled():\n",
    "    while True:\n",
    "        query = input(\"\\nEnter a query: \")\n",
    "        if query == \"exit\":\n",
    "            break\n",
    "        # Get the answer from the chain\n",
    "        answer = get_llm_generation_langchain(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-10T18:48:35.337004Z",
     "end_time": "2023-07-10T18:48:44.617330Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_llm_generation_langchain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mget_llm_generation_langchain\u001B[49m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhello\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'get_llm_generation_langchain' is not defined"
     ]
    }
   ],
   "source": [
    " get_llm_generation_langchain('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ce103d6601947f9b4d90ba14d1bcbfe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya\\miniconda3\\envs\\chatbot\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Aditya\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1373f881435d4a059e769397498e0d00"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23348c923ca841c58ac7d5ad847375dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9897e715f2d44bb99d80a0de78d1b7a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': [0.789967954158783, 0.5584042072296143], 'recall': [0.789967954158783, 0.58890300989151], 'f1': [0.789967954158783, 0.5732482671737671], 'hashcode': 'distilbert-base-uncased_L5_no-idf_version=0.3.12(hug_trans=4.30.2)'}\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T18:23:27.635470Z",
     "end_time": "2023-07-10T18:24:24.103975Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': [0.789967954158783, 0.5584042072296143], 'recall': [0.789967954158783, 0.58890300989151], 'f1': [0.789967954158783, 0.5732482671737671], 'hashcode': 'distilbert-base-uncased_L5_no-idf_version=0.3.12(hug_trans=4.30.2)'}\n"
     ]
    }
   ],
   "source": [
    "predictions = [\"hello world\", \"general kenobi\"]\n",
    "references = [\"goodnight moon\", \"the sun is shining\"]\n",
    "results = bertscore.compute(predictions=predictions, references=references, model_type=\"distilbert-base-uncased\")\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T18:33:23.962168Z",
     "end_time": "2023-07-10T18:33:24.016168Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # W&B env setup\n",
    "# os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
